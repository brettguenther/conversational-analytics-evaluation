"""Scaffolding for SQL-based evaluation metrics."""

from abc import ABC, abstractmethod

class SQLTextMetric(ABC):
    """Abstract base class for a SQL text evaluation metric."""

    @abstractmethod
    def measure(
        self,
        generated_sql: str,
        expected_sql: str,
    ) -> float:
        """Measures the quality of the generated SQL.

        Args:
            generated_sql: The SQL query generated by the agent.
            expected_sql: The expected (golden) SQL query.

        Returns:
            A score between 0.0 and 1.0, where 1.0 is a perfect match.
        """
        pass


class SQLExactMatch(SQLTextMetric):
    """Measures the exact string match between two SQL queries after normalization."""

    def measure(
        self, generated_sql: str, expected_sql: str, **kwargs
    ) -> float:
        """Compares two SQL queries for exact match after normalization."""
        if not generated_sql or not expected_sql:
            return 0.0
        # Normalize whitespace and case
        norm_gen = " ".join(generated_sql.lower().split())
        norm_exp = " ".join(expected_sql.lower().split())
        return 1.0 if norm_gen == norm_exp else 0.0


class SQLASTMatch(SQLTextMetric):
    """Placeholder for a metric that compares the AST of two SQL queries."""

    def measure(
        self, generated_sql: str, expected_sql: str, **kwargs
    ) -> float:
        """Compares the Abstract Syntax Trees of two SQL queries."""
        # TODO: Implement AST parsing and comparison using a library like sqlparse.
        print("AST matching not implemented yet.")
        return 0.0


def score_sql_text(
    generated_sql: str,
    expected_sql: str,
    metrics: list[SQLTextMetric],
) -> dict[str, float]:
    """Scores a SQL response using a list of metrics.

    Args:
        generated_sql: The SQL query generated by the agent.
        expected_sql: The expected (golden) SQL query.
        metrics: A list of SQLTextMetric objects to use for scoring.

    Returns:
        A dictionary of metric names to scores.
    """
    scores = {}
    for metric in metrics:
        metric_name = metric.__class__.__name__
        scores[metric_name] = metric.measure(
            generated_sql=generated_sql,
            expected_sql=expected_sql,
        )
    return scores